{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain langchain-community langchain-openai python-dotenv numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "model_35name = \"gpt-fake\"\n",
    "llm35 = ChatOpenAI(\n",
    "    model = model_35name,\n",
    "    openai_api_key = openai_api_key,\n",
    "    temperature = 0.5,\n",
    "    max_tokens = 1000\n",
    ") | DatetimeOutputParser()\n",
    "\n",
    "model_40name = \"gpt-4o\"\n",
    "llm40 = ChatOpenAI(\n",
    "    model = model_40name,\n",
    "    openai_api_key = openai_api_key,\n",
    "    temperature = 0.5,\n",
    "    max_tokens = 1000\n",
    ") | DatetimeOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm35_without_dt_parsing = ChatOpenAI(\n",
    "    model = model_35name,\n",
    "    openai_api_key = openai_api_key,\n",
    "    temperature = 0.1,\n",
    "    max_tokens = 1000\n",
    ") \n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    describe the {event}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "only_35_simple = prompt | llm35_without_dt_parsing\n",
    "\n",
    "try:\n",
    "    response = only_35_simple.invoke({\n",
    "        \"event\": \"The superbowl in 1994\"\n",
    "    })\n",
    "\n",
    "    print(response)\n",
    "except Exception as error:\n",
    "    print(f\"Error Occurred, Details {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You're an assistant who can answer the date time related analysis.\n",
    "    \n",
    "    If you do not know the answer, Please respond politely that I don't know how to answer your question.\n",
    "    \n",
    "    Question: What time was {event} in (%Y-%m-%dT%H:%M:%S.%fZ format) - Only return this value not anything else.   \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "only_35 = prompt | llm35\n",
    "\n",
    "try:\n",
    "    response = only_35.invoke({\n",
    "        \"event\": \"The superbowl in 1994\"\n",
    "    })\n",
    "\n",
    "    print(response)\n",
    "except Exception as error:\n",
    "    print(f\"Error Occurred, Details {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "fallback_4 = prompt | llm35.with_fallbacks([llm40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = fallback_4.invoke({\n",
    "        \"event\": \"The superbowl in 1994\"\n",
    "    })\n",
    "\n",
    "    print(response)\n",
    "except Exception as error:\n",
    "    print(f\"Error Occurred, Details {error}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
